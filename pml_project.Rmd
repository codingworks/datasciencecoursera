---
title: "Predict Quality of Weight Lifting Exercises"
author: "Rongqin Sheng"
output:
  html_document:
    keep_md: yes
  pdf_document: default
---

### Introduction

In this project, we will build a model to predict how well weight lifting exercises are performed. The data, which comes from this source: http://groupware.les.inf.puc-rio.br/har, was obtained from accelerometers on the belt, forearm, arm, and dumbell of 6 participants.

We will select the features and the model by exploratory data analyses and 3-fold cross validation.

### Exploratory Data Analyses 

Let's load the training data.
```{r}
train <- read.csv('pml-training.csv') 
```

The dataset has `r nrow(train)` rows and `r ncol(train)` columns. We are interested in column classe for classification and other 16 columns for features: 

- roll_belt 
- pitch_belt 
- yaw_belt 
- total_accel_belt 
- roll_arm 
- pitch_arm 
- yaw_arm 
- total_accel_arm 
- roll_dumbbell 
- pitch_dumbbell 
- yaw_dumbbell 
- total_accel_dumbbell 
- roll_forearm 
- pitch_forearm 
- yaw_forearm 
- total_accel_forearm

We find that the 16 features are closely related to classe. In Appendix, we show 3 scatter plots for a pair of features and classe. We can observe clear patterns related to classe in these plots. We will confirm our selection of the 16 features and the random forest method through cross validation.

### Cross Validation

Let's use 3-fold cross validation to evaluate the model using the random forest method on classe and the 16 features. 

```{r message = FALSE}
library(caret)
library(randomForest)
set.seed(123)
folds <- createFolds(y = train$classe, k = 3, list = TRUE, returnTrain = TRUE)
confusionMatrices = list()
for (i in 1:3) {
    training <- train[folds[[i]],]
    testing <- train[-folds[[i]],]
    set.seed(789)
    modelFit <- train(classe ~ roll_belt + pitch_belt + yaw_belt + total_accel_belt + 
        roll_arm + pitch_arm + yaw_arm + total_accel_arm + 
        roll_dumbbell + pitch_dumbbell + yaw_dumbbell + total_accel_dumbbell + 
        roll_forearm + pitch_forearm + yaw_forearm + total_accel_forearm,
        method = "rf", data = training)
    confusionMatrices[[i]] <- confusionMatrix(testing$classe, predict(modelFit, testing))
}
accuracyValues <- c(confusionMatrices[[1]]$overall[1],
                    confusionMatrices[[2]]$overall[1],
                    confusionMatrices[[3]]$overall[1])
averageAccuracy <- mean(accuracyValues)
```

Let's take a look at the accuracy values for the 3 model fits.

```{r}
accuracyValues
```

The average accuracy is `r averageAccuracy`. Therefore we have the expected out of sample accuracy `r averageAccuracy` for our final model.

### Final Model for Prediction

We are ready to build the final model.
```{r}
set.seed(789)
modelFitFinal <- train(classe ~ roll_belt + pitch_belt + yaw_belt + total_accel_belt + 
        roll_arm + pitch_arm + yaw_arm + total_accel_arm + 
        roll_dumbbell + pitch_dumbbell + yaw_dumbbell + total_accel_dumbbell + 
        roll_forearm + pitch_forearm + yaw_forearm + total_accel_forearm,
        method = "rf",data = train)
```

We can use the final model to make prediction on the testing dataset.
```{r}
test <- read.csv('pml-testing.csv')
results <- predict(modelFitFinal, test)
```


### Appendix 

```{r}
library(ggplot2)
ggplot(train, aes(y = total_accel_arm, x = roll_arm, color = classe)) + geom_point()

ggplot(train, aes(y = total_accel_belt, x = pitch_dumbbell, color = classe)) + geom_point()

ggplot(train, aes(y = total_accel_forearm, x = total_accel_belt, color = classe)) + geom_point()

```

